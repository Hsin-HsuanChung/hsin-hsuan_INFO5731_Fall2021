{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-992ca8f79052>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['review'])\n",
      "<ipython-input-4-992ca8f79052>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['review'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting-room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review Sentiment\n",
       "0  a stirring , funny and finally transporting re...         1\n",
       "1  apparently reassembled from the cutting-room f...         0\n",
       "2  they presume their audience wo n't sit still f...         0\n",
       "3  this is a visually stunning rumination on love...         1\n",
       "4  jonathan parker 's bartleby should have been t...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['review'])\n",
    "test_df = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['review'])\n",
    "\n",
    "train_df[['Sentiment','review']] = train_df[\"review\"].str.split(\" \", 1, expand=True)\n",
    "test_df[['Sentiment','review']] = test_df[\"review\"].str.split(\" \", 1, expand=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is one of polanski 's best films .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review Sentiment\n",
       "0     no movement , no yuks , not much of anything .         0\n",
       "1  a gob of drivel so sickly sweet , even the eag...         0\n",
       "2  gangs of new york is an unapologetic mess , wh...         0\n",
       "3  we never really feel involved with the story ,...         0\n",
       "4            this is one of polanski 's best films .         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chunghsinhsuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chunghsinhsuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopword=nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl= WordNetLemmatizer()\n",
    "# data cleaning\n",
    "def clean_text(text):\n",
    "    text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
    "    tokens = re.split('\\W+',text)\n",
    "    text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 13343)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>100minute</th>\n",
       "      <th>103minute</th>\n",
       "      <th>10course</th>\n",
       "      <th>10th</th>\n",
       "      <th>10thgrade</th>\n",
       "      <th>10year</th>\n",
       "      <th>10yearold</th>\n",
       "      <th>112minute</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>ziyi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombieland</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             100minute  103minute  10course  10th  10thgrade  10year  \\\n",
       "0  0.000000        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "1  0.048154        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "2  0.029784        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "3  0.049596        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "4  0.048782        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "\n",
       "   10yearold  112minute   12  ...  ziyi  zoe  zombie  zombieland  zone  \\\n",
       "0        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "1        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "2        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "3        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "4        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "\n",
       "   zoning  zoom  zwick  zzzzzzzzz  élan  \n",
       "0     0.0   0.0    0.0        0.0   0.0  \n",
       "1     0.0   0.0    0.0        0.0   0.0  \n",
       "2     0.0   0.0    0.0        0.0   0.0  \n",
       "3     0.0   0.0    0.0        0.0   0.0  \n",
       "4     0.0   0.0    0.0        0.0   0.0  \n",
       "\n",
       "[5 rows x 13343 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting train data into numerical usinf TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(train_df['review'])\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "X_tfidf_df=pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns=tfidf_vect.get_feature_names()\n",
    "X_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1821, 13343)\n"
     ]
    }
   ],
   "source": [
    "# converting the text data\n",
    "X_test_tfidf = tfidf_vect.transform(test_df['review'])\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "mnb = MultinomialNB()\n",
    "svm = LinearSVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# spliting the train data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_tfidf_df, train_df['Sentiment'].values,\n",
    "                                                test_size=0.2, random_state=42)\n",
    "model_mnb = mnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7955202312138728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       671\n",
      "           1       0.76      0.88      0.82       713\n",
      "\n",
      "    accuracy                           0.80      1384\n",
      "   macro avg       0.80      0.79      0.79      1384\n",
      "weighted avg       0.80      0.80      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(1)##\n",
    "# Accuracy using MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_mnb = model_mnb.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_mnb,y_test))\n",
    "print(classification_report(y_test,y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinominalNB: 0.7247054530288813\n"
     ]
    }
   ],
   "source": [
    "# MultinominalNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mnb, x_test, y_test, cv=10)\n",
    "print(\"MultinominalNB:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.791907514450867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       671\n",
      "           1       0.78      0.83      0.80       713\n",
      "\n",
      "    accuracy                           0.79      1384\n",
      "   macro avg       0.79      0.79      0.79      1384\n",
      "weighted avg       0.79      0.79      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(2)##\n",
    "# Accuracy using SVM\n",
    "model_svm = svm.fit(x_train,y_train)\n",
    "y_pred_svm = model_svm.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_svm,y_test))\n",
    "print(classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.7348034615785632\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svm, x_test, y_test, cv=10)\n",
    "print(\"SVM:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.740606936416185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       671\n",
      "           1       0.74      0.77      0.75       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.74      0.74      0.74      1384\n",
      "weighted avg       0.74      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(3)##\n",
    "# KNeighbors\n",
    "model_knn = knn.fit(x_train,y_train)\n",
    "y_pred_knn = model_knn.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_knn,y_test))\n",
    "print(classification_report(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.6675737670732979\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(knn, x_test, y_test, cv=10)\n",
    "print(\"KNN:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.661849710982659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       671\n",
      "           1       0.66      0.70      0.68       713\n",
      "\n",
      "    accuracy                           0.66      1384\n",
      "   macro avg       0.66      0.66      0.66      1384\n",
      "weighted avg       0.66      0.66      0.66      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(4)## \n",
    "# Decision tree\n",
    "model_dt = dt.fit(x_train,y_train)\n",
    "y_pred_dt = model_dt.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_dt,y_test))\n",
    "print(classification_report(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.6148159733083098\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "scores = cross_val_score(dt, x_test, y_test, cv=10)\n",
    "print(\"Decision tree:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7377167630057804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.71       671\n",
      "           1       0.71      0.82      0.76       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.74      0.74      0.73      1384\n",
      "weighted avg       0.74      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(5)##\n",
    "# Random Forest\n",
    "model_rf = rf.fit(x_train,y_train)\n",
    "y_pred_rf = model_rf.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_rf,y_test))\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest 0.6798769679908246\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "scores = cross_val_score(rf, x_test, y_test, cv=10)\n",
    "print(\"Random forest\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:08] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy 0.7182080924855492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67       671\n",
      "           1       0.69      0.84      0.75       713\n",
      "\n",
      "    accuracy                           0.72      1384\n",
      "   macro avg       0.73      0.71      0.71      1384\n",
      "weighted avg       0.73      0.72      0.71      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##(6)##\n",
    "# XGBoost\n",
    "model_xgb = xgb.fit(x_train,y_train)\n",
    "y_pred_xgb = model_xgb.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_xgb,y_test))\n",
    "print(classification_report(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:54] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:50] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:08] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: 0.6618027317276612\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "scores = cross_val_score(xgb, x_test, y_test, cv=10)\n",
    "print(\"XGBoost:\",scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-01e374d4c93f>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace('[^\\w\\s]','')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chunghsinhsuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chunghsinhsuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "df['Text'] = df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]','')\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop = stopwords.words('english')\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I feel so LUCKY to have found this used (phone...\n",
       "1    nice phone, nice up grade from my pantach revu...\n",
       "2                                         Very pleased\n",
       "3    It works good but it goes slow sometimes but i...\n",
       "4    Great phone to replace my lost phone. The only...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
    "names= tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunghsinhsuan/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({5: 153064,\n",
       "         1: 193792,\n",
       "         8: 14070,\n",
       "         2: 17260,\n",
       "         3: 5414,\n",
       "         6: 10812,\n",
       "         4: 6669,\n",
       "         0: 9151,\n",
       "         7: 3608})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##K Means##\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 9,init='k-means++', n_jobs = -1,max_iter=10000, random_state=50)\n",
    "model.fit(tfidf_vects)\n",
    "from collections import Counter\n",
    "Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER #1\n",
      "Key Features: ['love', 'it', 'phone', 'this', 'great', 'my', 'the', 'new']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CLUSTER #2\n",
      "Key Features: ['it', 'phone', 'and', 'the', 'very', 'good', 'great', 'nice']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CLUSTER #3\n",
      "Key Features: ['good', 'very', 'phone', 'product', 'price', 'it', 'is', 'thanks']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CLUSTER #4\n",
      "Key Features: ['perfect', 'condition', 'everything', 'works', 'was', 'it', 'phone', 'all']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CLUSTER #5\n",
      "Key Features: ['excelente', 'producto', 'telefono', 'gracias', 'recomendado', '100', 'celular', 'teléfono']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CLUSTER #6\n",
      "Key Features: ['the', 'it', 'and', 'to', 'phone', 'is', 'this', 'for']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "topn_features = 8\n",
    "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for cluster_num in range(6):\n",
    "    key_features = [names[i] for i in centroids[cluster_num, :topn_features]]\n",
    "    print('CLUSTER #'+str(cluster_num+1))\n",
    "    print('Key Features:', key_features)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.37759491e-04, 1.62726448e-05, 6.98619853e-06, ...,\n",
       "        5.06237163e-06, 1.15763776e-05, 3.94315939e-06],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_center=model.cluster_centers_\n",
    "cluster_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05744897581696309"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "silhouette_score = metrics.silhouette_score(tfidf_vects, model.labels_, metric='euclidean')\n",
    "silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DBSCAN##\n",
    "Text_reviews=[]\n",
    "for i in df['Reviews']:\n",
    "    Text_reviews.append(str(i).split())\n",
    "import gensim\n",
    "w2v_model=gensim.models.Word2Vec(Text_reviews, size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-f73a9b4ae665>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vector /= count\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vectors = []\n",
    "for i in Text_reviews:\n",
    "    vector = np.zeros(100)\n",
    "    count = 0\n",
    "    for word in i:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            vector += vec\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    vector /= count\n",
    "    vectors.append(vector)  \n",
    "vectors = np.array(vectors)\n",
    "vectors = np.nan_to_num(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "minPts = 2*100\n",
    "\n",
    "def lower_bound(nums, target): \n",
    "    l, r = 0, len(nums) - 1\n",
    "    while l <= r:\n",
    "        mid = int(l + (r - l) / 2)\n",
    "        if nums[mid] >= target:\n",
    "            r = mid - 1\n",
    "        else:\n",
    "            l = mid + 1\n",
    "    return l\n",
    "\n",
    "def compute200thnearestneighbour(x, data): \n",
    "    dists = []\n",
    "    for val in data:\n",
    "        dist = np.sum((x - val) **2 ) \n",
    "        if(len(dists) == 200 and dists[199] > dist): \n",
    "            l = int(lower_bound(dists, dist)) \n",
    "            if l < 200 and l >= 0 and dists[l] > dist:\n",
    "                dists[l] = dist\n",
    "        else:\n",
    "            dists.append(dist)\n",
    "            dists.sort()\n",
    "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
    "    return dists[199]\n",
    "\n",
    "vectors.shape\n",
    "\n",
    "neighbor = []\n",
    "for val in vectors[:300]:\n",
    "    neighbor.append(compute200thnearestneighbour(val, vectors[:300]))\n",
    "neighbor.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "# Plotting for the Elbow Method :\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.plot([x for x in range(len(neighbor))], neighbor)\n",
    "plt.xlabel(\"length\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Cluster Labels\n",
      "-1     197345\n",
      " 0     190876\n",
      " 1       1453\n",
      " 2       1261\n",
      " 3       2600\n",
      " 4        336\n",
      " 5       2331\n",
      " 6        772\n",
      " 7       2925\n",
      " 8        212\n",
      " 9        255\n",
      " 10       419\n",
      " 11      1212\n",
      " 12      1332\n",
      " 13       979\n",
      " 14       691\n",
      " 15       387\n",
      " 16       416\n",
      " 17       875\n",
      " 18       665\n",
      " 19       223\n",
      " 20       296\n",
      " 21       815\n",
      " 22       270\n",
      " 23       522\n",
      " 24       291\n",
      " 25       283\n",
      " 26       605\n",
      " 27       213\n",
      " 28       351\n",
      " 29       628\n",
      " 30       231\n",
      " 31       792\n",
      " 32       327\n",
      " 33       212\n",
      " 34       377\n",
      "Name: Reviews, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "model = DBSCAN(eps = 3, min_samples = minPts, n_jobs=-1)\n",
    "model.fit(vectors)\n",
    "df['DBSCAN Cluster Labels'] = model.labels_\n",
    "# Finding the number of reviews in each cluster\n",
    "print(df.groupby(['DBSCAN Cluster Labels'])['Reviews'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Hierarchical clustering##\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy\n",
    "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
    "plt.axhline(y=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, K-means considers every point in the dataset and uses that information to evolve the clustering over a series of iterations. Second, DBSCAN is based on density. It will find an unknown number of clusters of similar density. Third, Hierarchical clustering is used when we want to find the clusters inside the clusters. It is best when we want to find the hidden structures inside the data. Overall, when people need to work with huge datasets, K-means is efficient and is the better choice than DBSCAN and Hierarchical clustering. I spent a lot of time on DBSCAN and Hierarchical clustering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
